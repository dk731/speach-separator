{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 23:24:32.225211: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 23:24:32.264164: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 23:24:32.264713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 23:24:32.858815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-24 23:24:33.729207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 23:24:37.453296: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import kaldiio\n",
    "\n",
    "from scipy.signal import welch\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "# conda install -c conda-forge tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getenv(\"PROJECT_ROOT\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "CLIPS_PATH = os.getenv(\"CLIPS_PATH\")\n",
    "\n",
    "VALIDATED_LIST_PATH = os.path.join(os.getenv(\"CLIPS_META_PATH\"), \"validated.tsv\")\n",
    "XVECTOR_RESULT_PATH = os.getenv(\"XVECTOR_RESULT_PATH\")\n",
    "XVECTOR_SCP_PATH = os.path.join(XVECTOR_RESULT_PATH, \"xvector.scp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_xvectors = kaldiio.load_scp(XVECTOR_SCP_PATH)\n",
    "valid_speakers = set(speakers_xvectors.keys())\n",
    "\n",
    "raw_clips_meta = pd.read_table(VALIDATED_LIST_PATH)\n",
    "raw_clips_meta = raw_clips_meta[raw_clips_meta[\"client_id\"].isin(valid_speakers)]\n",
    "\n",
    "\n",
    "def get_path(row):\n",
    "    return f\"{CLIPS_PATH}/{row}.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    Concatenate,\n",
    "    LeakyReLU,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    AveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:42:37.090091: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 22:42:37.095127: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-24 22:42:37.096014: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.096202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.645GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2023-04-24 22:42:37.097242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-24 22:42:37.097335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-24 22:42:37.097373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-24 22:42:37.097397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-24 22:42:37.097442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-24 22:42:37.097478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-24 22:42:37.097500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-24 22:42:37.097522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-24 22:42:37.097612: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.097670: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.097678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-24 22:42:37.097738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-24 22:42:37.814026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-24 22:42:37.814060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-04-24 22:42:37.814065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-04-24 22:42:37.814547: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.814562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-24 22:42:37.814632: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.814724: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-24 22:42:37.814757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9495 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel_spectrogram_input (InputLay [(None, 64, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 256, 32)  320         mel_spectrogram_input[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 256, 32)  128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 32, 128, 32)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 128, 64)  18496       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 128, 64)  256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 64, 128)  73856       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 64, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 8, 32, 128)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_vector_input (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 33280)        0           flatten[0][0]                    \n",
      "                                                                 x_vector_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          4259968     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          33024       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          131584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,715,264\n",
      "Trainable params: 4,714,816\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "HYPER_PARAMS = {\n",
    "    # Model parameters\n",
    "    \"window-width\": 64,\n",
    "    \"mel-bands\": 256,\n",
    "    \"x-vector-dim\": 512,\n",
    "    # Training parameters\n",
    "    \"batch-size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"learning-rate\": 0.0001,\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "mel_spectrogram_shape = (\n",
    "    HYPER_PARAMS[\"window-width\"],\n",
    "    HYPER_PARAMS[\"mel-bands\"],\n",
    "    1,\n",
    ")  # Replace window_size and num_mel_bands with your values\n",
    "\n",
    "# Leaky ReLU activation function\n",
    "leaky_relu = LeakyReLU(alpha=0.2)\n",
    "\n",
    "# Mel-spectrogram input\n",
    "mel_spectrogram_input = Input(shape=mel_spectrogram_shape, name=\"mel_spectrogram_input\")\n",
    "\n",
    "# Convolutional layers\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=leaky_relu)(mel_spectrogram_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Convolutional layers\n",
    "x = Conv2D(32, (3, 3), padding=\"same\", activation=leaky_relu)(mel_spectrogram_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding=\"same\", activation=leaky_relu)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding=\"same\", activation=leaky_relu)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# X-vector input\n",
    "x_vector_input = Input(shape=(HYPER_PARAMS[\"x-vector-dim\"],), name=\"x_vector_input\")\n",
    "\n",
    "# Concatenate flattened CNN output with x-vector input\n",
    "combined_input = Concatenate()([x, x_vector_input])\n",
    "\n",
    "# Dense layers\n",
    "y = Dense(128, activation=leaky_relu)(combined_input)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(256, activation=leaky_relu)(y)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(256, activation=leaky_relu)(y)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(512, activation=leaky_relu)(y)\n",
    "output = Dense(HYPER_PARAMS[\"mel-bands\"], activation=\"linear\")(y)\n",
    "\n",
    "# Construct the model\n",
    "model = Model(inputs=[mel_spectrogram_input, x_vector_input], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=HYPER_PARAMS[\"learning-rate\"])\n",
    "loss_fn = MeanSquaredError()\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:42:39.658630: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-04-24 22:42:39.658678: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-04-24 22:42:39.658755: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2023-04-24 22:42:39.660776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2023-04-24 22:42:39.787614: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2023-04-24 22:42:39.787749: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplesLoader:\n",
    "    def __init__(self, audio_samples, x_vectors, batch_size, samples_coeficients):\n",
    "        self.audio_samples = audio_samples\n",
    "        self.x_vectors = x_vectors\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_coeficients = samples_coeficients\n",
    "\n",
    "        self.epoch_iterator = None\n",
    "        self.current_file = None\n",
    "        self.batch_leftover = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.epoch_iterator = raw_clips_meta.sample(frac=1).iterrows()\n",
    "        return self\n",
    "\n",
    "    # Returns batch of noisy and clean samples\n",
    "    def __next__(self):\n",
    "        sample_ind, sample_data = self.epoch_iterator.__next__()\n",
    "        sample_client = sample_data[\"client_id\"]\n",
    "        sample_path = get_path(sample_data[\"path\"])\n",
    "\n",
    "        print(f\"Loading sample {sample_ind} from {sample_path}\")\n",
    "\n",
    "        current_audio = tfio.audio.AudioIOTensor(sample_path)\n",
    "        return current_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_COEFICIENTS = {\n",
    "    \"raw\": 0.8,\n",
    "    \"empty\": 0.1,\n",
    "    \"noisy\": 0.4,\n",
    "    \"combined\": 0.1,\n",
    "    \"noisy_combined\": 0.1,\n",
    "}\n",
    "\n",
    "data_loader = SamplesLoader(raw_clips_meta, speakers_xvectors, HYPER_PARAMS[\"batch-size\"], SAMPLE_COEFICIENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7a59c0c8e4c76e48c46c1c2f7c84b3c07eeeded993e241eeb547ccfe8c6e2529f15b6f678cd48427f0d98ff2c939384ad694a539fc540ba435f290b6d1c95ffc'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = raw_clips_meta.sample(frac=1).iterrows()\n",
    "a.__next__()[1][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample 10287 from /home/user/commonvoice/en_Common_Voice_Corpus_1/clips/bd136bc43ddbfeb12dbb6321519b04d7d72841be7ce92dc0756daa20e1a3f8171097d31745b2bbc958378b77d5b4f1e13a303c7b9945664410944be7327ba2f0.mp3\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "unable to open file: libtensorflow_io.so, from paths: ['/home/user/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/home/user/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase18MakeSplitProvidersEPSt6vectorISt10unique_ptrINS0_13SplitProviderESt14default_deleteIS4_EESaIS7_EE']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n",
      "Cell \u001b[0;32mIn[105], line 25\u001b[0m, in \u001b[0;36mSamplesLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m sample_path \u001b[39m=\u001b[39m get_path(sample_data[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading sample \u001b[39m\u001b[39m{\u001b[39;00msample_ind\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00msample_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m current_audio \u001b[39m=\u001b[39m tfio\u001b[39m.\u001b[39;49maudio\u001b[39m.\u001b[39;49mAudioIOTensor(sample_path)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m current_audio\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/audio_ops.py:671\u001b[0m, in \u001b[0;36mAudioIOTensor.__init__\u001b[0;34m(self, filename, dtype)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    670\u001b[0m     \u001b[39massert\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mdtype must be provided in graph mode\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 671\u001b[0m resource \u001b[39m=\u001b[39m core_ops\u001b[39m.\u001b[39;49mio_audio_readable_init(filename)\n\u001b[1;32m    672\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    673\u001b[0m     shape, dtype, rate \u001b[39m=\u001b[39m core_ops\u001b[39m.\u001b[39mio_audio_readable_spec(resource)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:88\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, attrb)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attrb):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load(), attrb)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:84\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod \u001b[39m=\u001b[39m _load_library(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_library)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:69\u001b[0m, in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mNotFoundError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m         errs\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(e))\n\u001b[0;32m---> 69\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39munable to open file: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m, from paths: \u001b[39m\u001b[39m{\u001b[39;00mfilenames\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mcaused by: \u001b[39m\u001b[39m{\u001b[39;00merrs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unable to open file: libtensorflow_io.so, from paths: ['/home/user/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/home/user/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase18MakeSplitProvidersEPSt6vectorISt10unique_ptrINS0_13SplitProviderESt14default_deleteIS4_EESaIS7_EE']"
     ]
    }
   ],
   "source": [
    "b.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m train_steps_per_epoch \u001b[39m=\u001b[39m \u001b[39m2000\u001b[39m  \u001b[39m# Adjust this value based on your training set size\u001b[39;00m\n\u001b[1;32m      4\u001b[0m val_steps_per_epoch \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m  \u001b[39m# Adjust this value based on your validation set size\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39;49m(HYPER_PARAMS[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m]), desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTraining\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tqdm/notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    237\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[0;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[1;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tqdm/notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[1;32m    115\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "train_steps_per_epoch = 2000  # Adjust this value based on your training set size\n",
    "val_steps_per_epoch = 500  # Adjust this value based on your validation set size\n",
    "\n",
    "for epoch in tqdm(range(HYPER_PARAMS[\"epochs\"]), desc=\"Training\"):\n",
    "    pass\n",
    "    # Train on batches\n",
    "    # for batch_X_mel, batch_X_xvec, batch_y in train_dataset:\n",
    "    #     train_result = model.train_on_batch(\n",
    "    #         x=[batch_X_mel, batch_X_xvec], y=batch_y, reset_metrics=False\n",
    "    #     )\n",
    "\n",
    "    #     # Write train metrics to TensorBoard\n",
    "    #     with tensorboard_callback.as_default():\n",
    "    #         tf.summary.scalar(\"loss\", train_result, step=epoch)\n",
    "\n",
    "    # Validate on batches\n",
    "    # val_losses = []\n",
    "    # for batch_X_mel, batch_X_xvec, batch_y in val_dataset:\n",
    "    #     val_result = model.test_on_batch(x=[batch_X_mel, batch_X_xvec], y=batch_y)\n",
    "\n",
    "    #     # Collect validation losses\n",
    "    #     val_losses.append(val_result)\n",
    "\n",
    "    # Write validation metrics to TensorBoard\n",
    "    # mean_val_loss = np.mean(val_losses)\n",
    "    # with tensorboard_callback.as_default():\n",
    "    #     tf.summary.scalar(\"val_loss\", mean_val_loss, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
